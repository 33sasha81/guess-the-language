# guess-the-language
# Проект по определению языка текста с использованием биграммных моделей

## Описание проекта

Этот проект предназначен для определения языка текста на основе биграммных языковых моделей. Он позволяет обучить модели на корпусах текстов для пяти языков — английского, русского, немецкого, испанского и французского — и определить язык введенного текста, сравнивая его перплексию для каждой модели. Основная идея заключается в использовании статистических свойств биграмм (парного появления слов) для оценки вероятности текста в контексте конкретного языка. Репозиторий включает скрипты для загрузки корпусов, обучения моделей и запуска программы для определения языка.

## Структура репозитория

- `README.md` — описание проекта и инструкции по использованию.
- `download.py` — скрипт для загрузки корпусов текстов с Google Drive.
- `language_identification.py` — основной скрипт для определения языка текста с использованием обученных моделей.
- `train_models.py` — скрипт для обучения биграммных моделей и сохранения их на диск.

## Описание кода

### `download.py`

Скрипт отвечает за загрузку текстовых корпусов для пяти языков с Google Drive. Используется библиотека `gdown` для скачивания файлов по указанным ссылкам. Корпуса сохраняются в папку `data` с именами `eng_w.txt`, `rus_w.txt`, `deu_w.txt`, `spa_w.txt` и `fra_w.txt`. Если файл уже существует, повторная загрузка не выполняется.

### `train_models.py`

Этот скрипт обучает биграммные языковые модели для каждого из пяти языков. Основные смысловые части:

1. **Загрузка корпуса**: Функция `load_corpus` читает текстовый файл (включая сжатые `.gz`), разбивает текст на слова и возвращает их список.
2. **Обучение моделей**: Класс `BigramLanguageModel` подсчитывает частоты униграмм (отдельных слов) и биграмм (пар слов) из списка слов. Метод `probability` вычисляет вероятность появления слова после предыдущего на основе подсчитанных частот.
3. **Сохранение моделей**: Обученные модели сериализуются в файлы `.pkl` с помощью `pickle` для последующего использования.

### `language_identification.py`

Скрипт определяет язык введенного текста, используя обученные модели. Основные смысловые части:

1. **Загрузка моделей**: Функция `load_models` десериализует модели из файлов `.pkl` и возвращает словарь с моделями для каждого языка.
2. **Вычисление перплексии**: Функция `calculate_perplexity` оценивает, насколько хорошо модель предсказывает текст, вычисляя перплексию на основе логарифмов вероятностей биграмм.
3. **Определение языка**: Функция `identify_language` сравнивает перплексии текста для всех моделей и выбирает язык с наименьшей перплексией как наиболее вероятный.

## Использование

Для работы с проектом выполните следующие шаги:

1. **Загрузка корпусов**:
   ```bash
   python3 download.py
Скрипт загрузит корпуса текстов в папку data.

2. **Обучение моделей**:
   ```bash
   python3 train_models.py
Скрипт обучит биграммные модели и сохранит их в файлы .pkl.

3. **Запуск программы для определения языка**:
   ```bash
   python3 language_identification_gui.py
Запустится программа, которая позволит определить язык введенного текста.

## Источники

- **Корпуса текстов**, загруженные с Google Drive по следующим ссылкам:
  - Английский: [eng_w.txt](https://drive.google.com/uc?id=1MOdBYmKczmadRDLH1sMUYbBWtWhTFp9O)
  - Русский: [rus_w.txt](https://drive.google.com/uc?id=1H257C5Nf3-IsQ41HeNpYaPhgGXXGnrjU)
  - Немецкий: [deu_w.txt](https://drive.google.com/uc?id=1BKcdCKrYwy00XklRdf5FVkHYCOtOfgJF)
  - Испанский: [spa_w.txt](https://drive.google.com/uc?id=19Rcyk1zZOuai9Oh8N5f0szvjAW8lQzeY)
  - Французский: [fra_w.txt](https://drive.google.com/uc?id=12kMibFwZCxSfiyQczdbX4bYay3tCJvx8)

- **Используемые библиотеки**:
  - `gdown` — для загрузки файлов с Google Drive.
  - `pickle` — для сериализации и десериализации моделей.
  - Стандартные библиотеки Python (`os`, `collections`, `typing`, `math`).
